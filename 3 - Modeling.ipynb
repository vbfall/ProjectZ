{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import pandas\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.preprocessing import Imputer \n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 42\n",
    "TOL = 1e-5\n",
    "MAX_ITER = 1e5\n",
    "target = 'KWH'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>REGIONC</th>\n",
       "      <th>DIVISION</th>\n",
       "      <th>REPORTABLE_DOMAIN</th>\n",
       "      <th>TYPEHUQ</th>\n",
       "      <th>NWEIGHT</th>\n",
       "      <th>HDD65</th>\n",
       "      <th>CDD65</th>\n",
       "      <th>HDD30YR</th>\n",
       "      <th>CDD30YR</th>\n",
       "      <th>Climate_Region_Pub</th>\n",
       "      <th>...</th>\n",
       "      <th>IECC_Climate_Pub_3B-4B</th>\n",
       "      <th>IECC_Climate_Pub_3C</th>\n",
       "      <th>IECC_Climate_Pub_4A</th>\n",
       "      <th>IECC_Climate_Pub_4C</th>\n",
       "      <th>IECC_Climate_Pub_5A</th>\n",
       "      <th>IECC_Climate_Pub_5B-5C</th>\n",
       "      <th>IECC_Climate_Pub_6A-6B</th>\n",
       "      <th>IECC_Climate_Pub_7A-7B-7AK-8AK</th>\n",
       "      <th>IECC_Climate_Pub_nan</th>\n",
       "      <th>KWH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.356433</td>\n",
       "      <td>-0.130712</td>\n",
       "      <td>-0.095887</td>\n",
       "      <td>-1.391557</td>\n",
       "      <td>7.909538</td>\n",
       "      <td>0.144107</td>\n",
       "      <td>-0.406764</td>\n",
       "      <td>0.310213</td>\n",
       "      <td>-0.422437</td>\n",
       "      <td>1.036457</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.316109</td>\n",
       "      <td>1.618052</td>\n",
       "      <td>1.490477</td>\n",
       "      <td>-0.552874</td>\n",
       "      <td>-0.105539</td>\n",
       "      <td>0.533708</td>\n",
       "      <td>-1.056278</td>\n",
       "      <td>0.313309</td>\n",
       "      <td>-1.247470</td>\n",
       "      <td>1.777458</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.356433</td>\n",
       "      <td>-0.130712</td>\n",
       "      <td>0.270197</td>\n",
       "      <td>-0.552874</td>\n",
       "      <td>-0.381506</td>\n",
       "      <td>-1.257247</td>\n",
       "      <td>1.148720</td>\n",
       "      <td>-1.235898</td>\n",
       "      <td>1.057337</td>\n",
       "      <td>0.295456</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.316109</td>\n",
       "      <td>1.618052</td>\n",
       "      <td>1.490477</td>\n",
       "      <td>1.124492</td>\n",
       "      <td>0.727638</td>\n",
       "      <td>0.412901</td>\n",
       "      <td>-0.940829</td>\n",
       "      <td>0.252261</td>\n",
       "      <td>-1.126112</td>\n",
       "      <td>1.777458</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.316109</td>\n",
       "      <td>0.918547</td>\n",
       "      <td>0.880337</td>\n",
       "      <td>-0.552874</td>\n",
       "      <td>-0.823157</td>\n",
       "      <td>0.569518</td>\n",
       "      <td>-0.614750</td>\n",
       "      <td>0.604836</td>\n",
       "      <td>-0.581963</td>\n",
       "      <td>-1.186546</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6414</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 564 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    REGIONC  DIVISION  REPORTABLE_DOMAIN   TYPEHUQ   NWEIGHT     HDD65  \\\n",
       "0  0.356433 -0.130712          -0.095887 -1.391557  7.909538  0.144107   \n",
       "1  1.316109  1.618052           1.490477 -0.552874 -0.105539  0.533708   \n",
       "2  0.356433 -0.130712           0.270197 -0.552874 -0.381506 -1.257247   \n",
       "3  1.316109  1.618052           1.490477  1.124492  0.727638  0.412901   \n",
       "4  1.316109  0.918547           0.880337 -0.552874 -0.823157  0.569518   \n",
       "\n",
       "      CDD65   HDD30YR   CDD30YR  Climate_Region_Pub  ...  \\\n",
       "0 -0.406764  0.310213 -0.422437            1.036457  ...   \n",
       "1 -1.056278  0.313309 -1.247470            1.777458  ...   \n",
       "2  1.148720 -1.235898  1.057337            0.295456  ...   \n",
       "3 -0.940829  0.252261 -1.126112            1.777458  ...   \n",
       "4 -0.614750  0.604836 -0.581963           -1.186546  ...   \n",
       "\n",
       "   IECC_Climate_Pub_3B-4B  IECC_Climate_Pub_3C  IECC_Climate_Pub_4A  \\\n",
       "0                     0.0                  0.0                  1.0   \n",
       "1                     0.0                  0.0                  0.0   \n",
       "2                     0.0                  0.0                  0.0   \n",
       "3                     0.0                  0.0                  0.0   \n",
       "4                     0.0                  0.0                  0.0   \n",
       "\n",
       "   IECC_Climate_Pub_4C  IECC_Climate_Pub_5A  IECC_Climate_Pub_5B-5C  \\\n",
       "0                  0.0                  0.0                     0.0   \n",
       "1                  1.0                  0.0                     0.0   \n",
       "2                  0.0                  0.0                     0.0   \n",
       "3                  1.0                  0.0                     0.0   \n",
       "4                  0.0                  0.0                     1.0   \n",
       "\n",
       "   IECC_Climate_Pub_6A-6B  IECC_Climate_Pub_7A-7B-7AK-8AK  \\\n",
       "0                     0.0                             0.0   \n",
       "1                     0.0                             0.0   \n",
       "2                     0.0                             0.0   \n",
       "3                     0.0                             0.0   \n",
       "4                     0.0                             0.0   \n",
       "\n",
       "   IECC_Climate_Pub_nan    KWH  \n",
       "0                   0.0  23103  \n",
       "1                   0.0  12018  \n",
       "2                   0.0   9612  \n",
       "3                   0.0   7154  \n",
       "4                   0.0   6414  \n",
       "\n",
       "[5 rows x 564 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pandas.read_csv('data/train_data.csv')\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pandas.read_csv('data/test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Variable Label</th>\n",
       "      <th>Variable Order in File</th>\n",
       "      <th>Variable Type</th>\n",
       "      <th>Length</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Variable Name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DOEID</th>\n",
       "      <td>Unique identifier for each respondent</td>\n",
       "      <td>1</td>\n",
       "      <td>Character</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>REGIONC</th>\n",
       "      <td>Census Region</td>\n",
       "      <td>2</td>\n",
       "      <td>Numeric</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DIVISION</th>\n",
       "      <td>Census Division</td>\n",
       "      <td>3</td>\n",
       "      <td>Numeric</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>REPORTABLE_DOMAIN</th>\n",
       "      <td>Reportable states and groups of states</td>\n",
       "      <td>4</td>\n",
       "      <td>Numeric</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TYPEHUQ</th>\n",
       "      <td>Type of housing unit</td>\n",
       "      <td>5</td>\n",
       "      <td>Numeric</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Variable Label  \\\n",
       "Variable Name                                               \n",
       "DOEID               Unique identifier for each respondent   \n",
       "REGIONC                                     Census Region   \n",
       "DIVISION                                  Census Division   \n",
       "REPORTABLE_DOMAIN  Reportable states and groups of states   \n",
       "TYPEHUQ                              Type of housing unit   \n",
       "\n",
       "                   Variable Order in File Variable Type  Length  \n",
       "Variable Name                                                    \n",
       "DOEID                                   1     Character       5  \n",
       "REGIONC                                 2       Numeric       8  \n",
       "DIVISION                                3       Numeric       8  \n",
       "REPORTABLE_DOMAIN                       4       Numeric       8  \n",
       "TYPEHUQ                                 5       Numeric       8  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layout = pandas.read_csv('data/public_layout.csv', index_col='Variable Name')\n",
    "layout.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actual modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're leveraging Scikit Learn for some basic algorithms that should give us decent results, at least as a benchmark. It also offers evaluation by R2 correlation, which is adequate for a regression case like this, so let's use that to compare a few different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = train_data.columns.drop(target)\n",
    "assert(len(train_data.columns) - len(features) == 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear regression, no regularization\n",
    "(not promising... but a quick first try)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialize and fit model\n",
    "model_linear_full = LinearRegression()\n",
    "model_linear_full.fit(train_data[features], numpy.ravel(train_data[target]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-9.785760207702073e+19"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#How does it generalize?\n",
    "model_linear_full.score(test_data[features], numpy.ravel(test_data[target]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow. Hard to see a model so bad. But it can be overfitting, with this data/feature ratio, so let's try removing some features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9664, 36)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Pruning features\n",
    "linear_feature_selector_standard = SelectFromModel(model_linear_full, prefit=True, threshold='mean')\n",
    "select_train_data_linear_standard = linear_feature_selector_standard.transform(train_data[features])\n",
    "select_test_data_linear_standard = linear_feature_selector_standard.transform(test_data[features])\n",
    "select_train_data_linear_standard.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only 36 features have coefficients above the mean. Let's try using those."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.241432175334158e+23"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fitting with selected features\n",
    "model_linear_select_standard = LinearRegression()\n",
    "model_linear_select_standard.fit(select_train_data_linear_standard, numpy.ravel(train_data[target]))\n",
    "model_linear_select_standard.score(select_test_data_linear_standard, numpy.ravel(test_data[target]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Way worse. But just to make sure, perhaps feature selection should have been even stricter. Let's try with a lower threshold than the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9664, 21)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Pruning features\n",
    "feature_threshold = 2.1*1e14\n",
    "linear_feature_selector_restrictive = SelectFromModel(model_linear_full, prefit=True, threshold=feature_threshold)\n",
    "select_train_data_linear_restrictive = linear_feature_selector_restrictive.transform(train_data[features])\n",
    "select_test_data_linear_restrictive = linear_feature_selector_restrictive.transform(test_data[features])\n",
    "select_train_data_linear_restrictive.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14553103242031762"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fitting with selected features\n",
    "model_linear_select_restrictive = LinearRegression()\n",
    "model_linear_select_restrictive.fit(select_train_data_linear_restrictive, numpy.ravel(train_data[target]))\n",
    "model_linear_select_restrictive.score(select_test_data_linear_restrictive, numpy.ravel(test_data[target]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some predictive power, but far from useful. Let's try something else."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(criterion='friedman_mse', max_depth=None,\n",
       "                      max_features=None, max_leaf_nodes=None,\n",
       "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                      min_samples_leaf=1, min_samples_split=2,\n",
       "                      min_weight_fraction_leaf=0.0, presort=False,\n",
       "                      random_state=42, splitter='best')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fitting with all features\n",
    "model_tree_full = DecisionTreeRegressor(random_state=RANDOM_SEED, criterion='friedman_mse') #friedman_mse criterion proves more consistent than others\n",
    "model_tree_full.fit(train_data[features], numpy.ravel(train_data[target]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5825027849166835"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#How does it generalize?\n",
    "model_tree_full.score(test_data[features], numpy.ravel(test_data[target]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected for this case, much better than Linear Regression, by nature of the algorithm being a better fit to this data.\n",
    "\n",
    "Still a long way to go. Perhaps some feature selection can add value? Reduce overfitting?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9664, 30)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Pruning features\n",
    "tree_feature_selector_standard = SelectFromModel(model_tree_full, prefit=True)\n",
    "select_train_data_tree_standard = tree_feature_selector_standard.transform(train_data[features])\n",
    "select_test_data_tree_standard = tree_feature_selector_standard.transform(test_data[features])\n",
    "select_train_data_tree_standard.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A mere 30 features above mean. Let's check results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6982857640989614"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fitting with selected features\n",
    "model_tree_select_standard = DecisionTreeRegressor(random_state=RANDOM_SEED,criterion='friedman_mse')\n",
    "model_tree_select_standard.fit(select_train_data_tree_standard, numpy.ravel(train_data[target]))\n",
    "model_tree_select_standard.score(select_test_data_tree_standard, numpy.ravel(test_data[target]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A lot better, with a much lighter model.\n",
    "\n",
    "If a Decision Tree performed well, perhaps a Random Forest will do even better?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vbfal\\.conda\\envs\\ProjectZ\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   12.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    9.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    5.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:   49.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:   49.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:   48.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:  8.3min finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:  8.2min finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:  8.2min finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed: 13.5min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([  1.31092413,   9.16959222,  49.46776152, 494.24941214]),\n",
       " 'std_fit_time': array([0.02013023, 2.96559284, 0.30510673, 1.60275121]),\n",
       " 'mean_score_time': array([0.01800354, 0.02200143, 0.0770069 , 0.72271657]),\n",
       " 'std_score_time': array([2.24783192e-06, 8.04165779e-03, 1.63745010e-03, 6.59985933e-03]),\n",
       " 'param_n_estimators': masked_array(data=[1, 10, 100, 1000],\n",
       "              mask=[False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'n_estimators': 1},\n",
       "  {'n_estimators': 10},\n",
       "  {'n_estimators': 100},\n",
       "  {'n_estimators': 1000}],\n",
       " 'split0_test_score': array([0.51523358, 0.8113915 , 0.82939925, 0.83245291]),\n",
       " 'split1_test_score': array([0.59538272, 0.81447893, 0.8409781 , 0.84630467]),\n",
       " 'split2_test_score': array([0.65782056, 0.79272343, 0.80602318, 0.80831055]),\n",
       " 'mean_test_score': array([0.58947127, 0.80619849, 0.82546725, 0.82902307]),\n",
       " 'std_test_score': array([0.05836226, 0.00961058, 0.01453797, 0.01569876]),\n",
       " 'rank_test_score': array([4, 3, 2, 1])}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Quick hyperparameter search - how many forests in the tree to optimize the score / time balance?\n",
    "tune_parameters = {'n_estimators':[1,10,100,1000]}\n",
    "model_forest = RandomForestRegressor(random_state=RANDOM_SEED, verbose=1)\n",
    "cross_validation_forest = GridSearchCV(model_forest, tune_parameters, scoring='r2', return_train_score=False)\n",
    "cross_validation_forest.fit(train_data[features], numpy.ravel(train_data[target]))\n",
    "cross_validation_forest.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='friedman_mse', max_depth=None,\n",
       "                      max_features='auto', max_leaf_nodes=None,\n",
       "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                      min_samples_leaf=1, min_samples_split=2,\n",
       "                      min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                      n_jobs=None, oob_score=False, random_state=42, verbose=0,\n",
       "                      warm_start=False)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fitting with all features - for the sake of balance between time and efficiency, let's go with 100 estimators\n",
    "model_forest_full = RandomForestRegressor(random_state=RANDOM_SEED, criterion='friedman_mse',\n",
    "                                          n_estimators=100)\n",
    "model_forest_full.fit(train_data[features], numpy.ravel(train_data[target]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8634460453481361"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#How does it generalize?\n",
    "model_forest_full.score(test_data[features], numpy.ravel(test_data[target]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considerably better than a single Decision Tree, as expected. Already something that can be used.\n",
    "\n",
    "Can we reduce the number of features and keep the score high?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9664, 36)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Pruning features\n",
    "forest_feature_selector_standard = SelectFromModel(model_forest_full, prefit=True)\n",
    "select_train_data_forest_standard = forest_feature_selector_standard.transform(train_data[features])\n",
    "select_test_data_forest_standard = forest_feature_selector_standard.transform(test_data[features])\n",
    "select_train_data_forest_standard.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar order of magnitude as the Decision Tree. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8683030569334925"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fitting with selected features\n",
    "model_forest_select_standard = RandomForestRegressor(random_state=RANDOM_SEED, criterion='friedman_mse',\n",
    "                                                     n_estimators=100)\n",
    "model_forest_select_standard.fit(select_train_data_forest_standard, numpy.ravel(train_data[target]))\n",
    "model_forest_select_standard.score(select_test_data_forest_standard, numpy.ravel(test_data[target]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not much gain on performance, but model is 90% smaller."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vbfal\\.conda\\envs\\ProjectZ\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.089993  , 0.09033354, 0.08266679, 0.08899919, 0.08334422]),\n",
       " 'std_fit_time': array([0.00963704, 0.00579266, 0.01155768, 0.00282744, 0.0066593 ]),\n",
       " 'mean_score_time': array([0.00433771, 0.0043354 , 0.00400146, 0.00466935, 0.00400345]),\n",
       " 'std_score_time': array([4.74799983e-04, 4.70527668e-04, 1.32507737e-06, 4.71146214e-04,\n",
       "        2.43399824e-06]),\n",
       " 'param_alpha': masked_array(data=[0.01, 0.1, 1, 10, 100],\n",
       "              mask=[False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'alpha': 0.01},\n",
       "  {'alpha': 0.1},\n",
       "  {'alpha': 1},\n",
       "  {'alpha': 10},\n",
       "  {'alpha': 100}],\n",
       " 'split0_test_score': array([0.83705703, 0.83721972, 0.83777963, 0.83970515, 0.83858617]),\n",
       " 'split1_test_score': array([0.84470482, 0.84486461, 0.84581922, 0.84867093, 0.84715643]),\n",
       " 'split2_test_score': array([0.87952809, 0.87953759, 0.87972853, 0.87977875, 0.87478885]),\n",
       " 'mean_test_score': array([0.85376159, 0.85387225, 0.85444074, 0.85604992, 0.85350894]),\n",
       " 'std_test_score': array([0.01848387, 0.01841317, 0.01817855, 0.01717217, 0.01544747]),\n",
       " 'rank_test_score': array([4, 3, 2, 1, 5])}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Another quick hyperparameter search\n",
    "tune_parameters = {'alpha':[0.01, 0.1, 1, 10, 100]}\n",
    "model_ridge = Ridge(random_state=RANDOM_SEED, tol=TOL, max_iter=MAX_ITER)\n",
    "cross_validation_ridge = GridSearchCV(model_ridge, tune_parameters, scoring='r2', return_train_score=False)\n",
    "cross_validation_ridge.fit(train_data[features], numpy.ravel(train_data[target]))\n",
    "cross_validation_ridge.cv_results_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Relatively close across alpha values. Let's take the theoretical best one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=10, copy_X=True, fit_intercept=True, max_iter=100000.0,\n",
       "      normalize=False, random_state=42, solver='auto', tol=1e-05)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fitting with all features\n",
    "model_ridge_full = Ridge(random_state=RANDOM_SEED, tol=TOL, max_iter=MAX_ITER, alpha=10)\n",
    "model_ridge_full.fit(train_data[features],numpy.ravel(train_data[target]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8668089944859985"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#How does it generalize?\n",
    "model_ridge_full.score(test_data[features], numpy.ravel(test_data[target]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On par with a Random Forest. Does a lighter model work as well?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9664, 141)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Pruning features\n",
    "ridge_feature_selector_standard = SelectFromModel(model_ridge_full, prefit=True)\n",
    "select_train_data_ridge_standard = ridge_feature_selector_standard.transform(train_data[features])\n",
    "select_test_data_ridge_standard = ridge_feature_selector_standard.transform(test_data[features])\n",
    "select_train_data_ridge_standard.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8663116730585897"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fitting with selected features\n",
    "model_ridge_select_standard = Ridge(random_state=RANDOM_SEED, tol=TOL, max_iter=MAX_ITER, alpha=10)\n",
    "model_ridge_select_standard.fit(select_train_data_ridge_standard, numpy.ravel(train_data[target]))\n",
    "model_ridge_select_standard.score(select_test_data_ridge_standard, numpy.ravel(test_data[target]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar performance, but didn't get as much size benefit as the random forest model. Perhaps we can prune farther and still keep performance? Let's try to match the last random forest order of magnitude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9664, 34)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Pruning features\n",
    "feature_threshold = 7*1e2\n",
    "ridge_feature_selector_restrictive = SelectFromModel(model_ridge_full, prefit=True, threshold=feature_threshold)\n",
    "select_train_data_ridge_restrictive = ridge_feature_selector_restrictive.transform(train_data[features])\n",
    "select_test_data_ridge_restrictive = ridge_feature_selector_restrictive.transform(test_data[features])\n",
    "select_train_data_ridge_restrictive.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.848165008881888"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fitting with selected features\n",
    "model_ridge_select_restrictive = Ridge(random_state=RANDOM_SEED, tol=TOL, max_iter=MAX_ITER, alpha=10)\n",
    "model_ridge_select_restrictive.fit(select_train_data_ridge_restrictive, numpy.ravel(train_data[target]))\n",
    "model_ridge_select_restrictive.score(select_test_data_ridge_restrictive, numpy.ravel(test_data[target]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the Ridge regression loses more performance than the Random Forest on similar pruning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choosing model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chosing between the Random Forest and the Ridge Regression at this point depends on the constraints present. Ridge Regression, even without pruning, runs inference one order of magnitude faster than the Random Forest, as indicated by the numbers above. However to match the performance it will require more data and computing power on inference time, so this might be a limitation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Determine a theoretical upper performance limit for the model - there is a limit to the predictive power of modeling given a certain dataset. If current models are close to that limit, it may not be worth pursuing more complex modeling.\n",
    "\n",
    "\n",
    "2. Given room to the theoretical performance, or its uncertainty, attempt two more laboursome / compute-heavy approaches:\n",
    "\n",
    "    a. Detailed manual feature engineering, looking through the long list of variables and thinking of new, composed values to capture non-linear relationships\n",
    "    \n",
    "    b. More advanced non-linear modeling leveraging neural networks. With the current dataset type a regular feed-forward / MLP architecture could be tested, albeit nothing so far particularly feeds the belief that its performance would be better than the models above. If in the future we acquire sequence-like data (such as time-based data more granular than year for example), recurrent network variations might prove interesting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
